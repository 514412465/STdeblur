================ Training Loss (Wed Jun 13 06:37:34 2018) ================
================ Training Loss (Wed Jun 13 06:38:45 2018) ================
(epoch: 1, iters: 100, time: 1.695) G_GAN: 46.948 G_L1: 1396.761 D_real+fake: -44.274 
(epoch: 1, iters: 200, time: 1.595) G_GAN: 27.182 G_L1: 1583.297 D_real+fake: -38.143 
(epoch: 1, iters: 300, time: 1.593) G_GAN: 18.699 G_L1: 825.713 D_real+fake: -33.701 
(epoch: 1, iters: 400, time: 1.600) G_GAN: 13.176 G_L1: 1228.240 D_real+fake: -29.845 
================ Training Loss (Wed Jun 13 06:48:11 2018) ================
(epoch: 1, iters: 100, time: 2.270) G_GAN: 21.743 G_L1: 1416.488 D_real+fake: -28.487 
(epoch: 1, iters: 200, time: 1.606) G_GAN: 15.728 G_L1: 295.996 D_real+fake: -19.851 
(epoch: 1, iters: 300, time: 1.602) G_GAN: 11.394 G_L1: 1708.725 D_real+fake: -22.737 
(epoch: 1, iters: 400, time: 1.625) G_GAN: -3.198 G_L1: 1675.928 D_real+fake: -16.328 
(epoch: 1, iters: 500, time: 1.603) G_GAN: -5.673 G_L1: 1128.949 D_real+fake: -13.308 
(epoch: 1, iters: 600, time: 1.594) G_GAN: 10.743 G_L1: 759.651 D_real+fake: -22.405 
(epoch: 1, iters: 700, time: 1.598) G_GAN: -10.544 G_L1: 1836.521 D_real+fake: -10.723 
(epoch: 1, iters: 800, time: 1.604) G_GAN: -7.975 G_L1: 1553.941 D_real+fake: -15.272 
(epoch: 1, iters: 900, time: 1.623) G_GAN: -4.191 G_L1: 1052.792 D_real+fake: -6.236 
(epoch: 1, iters: 1000, time: 1.589) G_GAN: 0.846 G_L1: 185.535 D_real+fake: -5.105 
(epoch: 1, iters: 1100, time: 1.592) G_GAN: -4.701 G_L1: 1143.833 D_real+fake: -8.713 
(epoch: 2, iters: 49, time: 1.599) G_GAN: 12.071 G_L1: 1454.327 D_real+fake: -11.334 
(epoch: 2, iters: 149, time: 1.611) G_GAN: 15.759 G_L1: 869.573 D_real+fake: -3.611 
(epoch: 2, iters: 249, time: 1.613) G_GAN: 11.604 G_L1: 1362.767 D_real+fake: -6.872 
(epoch: 2, iters: 349, time: 1.614) G_GAN: 8.429 G_L1: 1806.717 D_real+fake: -7.442 
(epoch: 2, iters: 449, time: 1.606) G_GAN: 9.145 G_L1: 764.313 D_real+fake: -3.201 
(epoch: 2, iters: 549, time: 1.572) G_GAN: -1.962 G_L1: 233.862 D_real+fake: -3.340 
(epoch: 2, iters: 649, time: 1.595) G_GAN: 13.240 G_L1: 1304.924 D_real+fake: -6.246 
(epoch: 2, iters: 749, time: 1.613) G_GAN: 15.414 G_L1: 1038.282 D_real+fake: -4.986 
(epoch: 2, iters: 849, time: 1.615) G_GAN: 2.332 G_L1: 1453.564 D_real+fake: -6.088 
(epoch: 2, iters: 949, time: 1.628) G_GAN: 9.548 G_L1: 133.221 D_real+fake: -0.616 
(epoch: 2, iters: 1049, time: 1.632) G_GAN: 15.624 G_L1: 931.491 D_real+fake: -2.417 
(epoch: 2, iters: 1149, time: 1.601) G_GAN: 14.974 G_L1: 909.177 D_real+fake: -4.782 
(epoch: 3, iters: 98, time: 1.620) G_GAN: 13.558 G_L1: 1089.414 D_real+fake: -4.108 
(epoch: 3, iters: 198, time: 1.604) G_GAN: 15.063 G_L1: 648.391 D_real+fake: -2.916 
(epoch: 3, iters: 298, time: 1.634) G_GAN: 17.972 G_L1: 708.026 D_real+fake: -2.019 
(epoch: 3, iters: 398, time: 1.620) G_GAN: 12.364 G_L1: 1460.474 D_real+fake: -4.616 
(epoch: 3, iters: 498, time: 1.605) G_GAN: 11.982 G_L1: 734.291 D_real+fake: -2.345 
(epoch: 3, iters: 598, time: 1.620) G_GAN: 22.395 G_L1: 609.291 D_real+fake: -3.813 
(epoch: 3, iters: 698, time: 1.598) G_GAN: 14.855 G_L1: 905.899 D_real+fake: -2.810 
(epoch: 3, iters: 798, time: 1.615) G_GAN: 21.764 G_L1: 320.070 D_real+fake: -1.584 
(epoch: 3, iters: 898, time: 1.603) G_GAN: 16.556 G_L1: 1074.709 D_real+fake: -3.988 
(epoch: 3, iters: 998, time: 1.579) G_GAN: 15.821 G_L1: 373.579 D_real+fake: -1.933 
(epoch: 3, iters: 1098, time: 1.587) G_GAN: 12.187 G_L1: 379.674 D_real+fake: -1.526 
(epoch: 4, iters: 47, time: 1.600) G_GAN: 15.830 G_L1: 519.005 D_real+fake: -2.439 
(epoch: 4, iters: 147, time: 1.572) G_GAN: 16.538 G_L1: 181.972 D_real+fake: -0.844 
(epoch: 4, iters: 247, time: 1.601) G_GAN: 21.186 G_L1: 496.981 D_real+fake: -1.484 
(epoch: 4, iters: 347, time: 1.566) G_GAN: 11.910 G_L1: 248.535 D_real+fake: -0.568 
(epoch: 4, iters: 447, time: 1.607) G_GAN: 18.132 G_L1: 1002.097 D_real+fake: -4.131 
(epoch: 4, iters: 547, time: 1.582) G_GAN: 20.910 G_L1: 217.821 D_real+fake: -2.239 
(epoch: 4, iters: 647, time: 1.596) G_GAN: 13.891 G_L1: 1688.891 D_real+fake: -7.948 
(epoch: 4, iters: 747, time: 1.602) G_GAN: 16.935 G_L1: 1416.236 D_real+fake: -6.142 
(epoch: 4, iters: 847, time: 1.608) G_GAN: 23.265 G_L1: 1298.809 D_real+fake: -5.680 
(epoch: 4, iters: 947, time: 1.571) G_GAN: 18.277 G_L1: 2079.899 D_real+fake: -9.562 
(epoch: 4, iters: 1047, time: 1.595) G_GAN: 16.478 G_L1: 511.327 D_real+fake: -1.610 
(epoch: 4, iters: 1147, time: 1.580) G_GAN: 20.414 G_L1: 1029.860 D_real+fake: -4.173 
(epoch: 5, iters: 96, time: 1.600) G_GAN: 18.492 G_L1: 243.737 D_real+fake: -0.940 
(epoch: 5, iters: 196, time: 1.569) G_GAN: 21.484 G_L1: 264.860 D_real+fake: -1.548 
(epoch: 5, iters: 296, time: 1.571) G_GAN: 17.451 G_L1: 1022.949 D_real+fake: -6.238 
(epoch: 5, iters: 396, time: 1.603) G_GAN: 16.017 G_L1: 1249.566 D_real+fake: -5.705 
================ Training Loss (Wed Jun 13 08:31:41 2018) ================
(epoch: 1, iters: 100, time: 1.545) G_GAN: 8.379 G_L1: 1601.231 D_real+fake: -21.938 
(epoch: 1, iters: 200, time: 1.560) G_GAN: 9.342 G_L1: 1126.791 D_real+fake: -18.064 
(epoch: 1, iters: 300, time: 1.567) G_GAN: 1.475 G_L1: 909.307 D_real+fake: -16.570 
================ Training Loss (Wed Jun 13 08:41:41 2018) ================
(epoch: 1, iters: 100, time: 1.553) G_GAN: 4.906 G_L1: 1055.140 D_real+fake: -15.972 
(epoch: 1, iters: 200, time: 1.576) G_GAN: 10.813 G_L1: 708.850 D_real+fake: -15.023 
(epoch: 1, iters: 300, time: 1.559) G_GAN: 1.456 G_L1: 221.824 D_real+fake: -11.840 
(epoch: 1, iters: 400, time: 1.580) G_GAN: -6.473 G_L1: 103.429 D_real+fake: -6.346 
(epoch: 1, iters: 500, time: 1.566) G_GAN: -2.869 G_L1: 949.656 D_real+fake: -7.893 
(epoch: 1, iters: 600, time: 1.563) G_GAN: -5.077 G_L1: 883.965 D_real+fake: -7.356 
(epoch: 1, iters: 700, time: 1.578) G_GAN: -2.120 G_L1: 1228.569 D_real+fake: -10.177 
(epoch: 1, iters: 800, time: 1.583) G_GAN: -6.757 G_L1: 792.650 D_real+fake: -7.387 
(epoch: 1, iters: 900, time: 1.586) G_GAN: -5.417 G_L1: 229.525 D_real+fake: -3.744 
(epoch: 1, iters: 1000, time: 1.594) G_GAN: -4.618 G_L1: 1860.736 D_real+fake: -8.097 
(epoch: 1, iters: 1100, time: 1.574) G_GAN: -5.945 G_L1: 450.513 D_real+fake: -5.493 
(epoch: 2, iters: 49, time: 1.575) G_GAN: -0.939 G_L1: 848.133 D_real+fake: -5.095 
(epoch: 2, iters: 149, time: 1.554) G_GAN: -10.414 G_L1: 83.650 D_real+fake: -4.110 
(epoch: 2, iters: 249, time: 1.586) G_GAN: -0.444 G_L1: 1344.118 D_real+fake: -8.087 
(epoch: 2, iters: 349, time: 1.582) G_GAN: 0.736 G_L1: 1763.882 D_real+fake: -10.615 
(epoch: 2, iters: 449, time: 1.538) G_GAN: -4.996 G_L1: 975.832 D_real+fake: -7.307 
(epoch: 2, iters: 549, time: 1.572) G_GAN: -8.798 G_L1: 472.120 D_real+fake: -4.478 
(epoch: 2, iters: 649, time: 1.573) G_GAN: -5.319 G_L1: 1019.764 D_real+fake: -6.166 
(epoch: 2, iters: 749, time: 1.589) G_GAN: -3.941 G_L1: 1768.625 D_real+fake: -8.714 
(epoch: 2, iters: 849, time: 1.590) G_GAN: -6.841 G_L1: 1683.377 D_real+fake: -8.878 
(epoch: 2, iters: 949, time: 1.591) G_GAN: -8.302 G_L1: 105.480 D_real+fake: -1.744 
(epoch: 2, iters: 1049, time: 1.584) G_GAN: -7.711 G_L1: 1386.974 D_real+fake: -6.112 
(epoch: 2, iters: 1149, time: 1.577) G_GAN: -7.862 G_L1: 58.020 D_real+fake: -1.643 
(epoch: 3, iters: 98, time: 1.609) G_GAN: 0.913 G_L1: 1375.355 D_real+fake: -8.128 
(epoch: 3, iters: 198, time: 1.599) G_GAN: -0.341 G_L1: 1481.456 D_real+fake: -11.313 
(epoch: 3, iters: 298, time: 1.573) G_GAN: -2.720 G_L1: 1491.690 D_real+fake: -8.394 
(epoch: 3, iters: 398, time: 1.581) G_GAN: -5.651 G_L1: 933.988 D_real+fake: -4.210 
(epoch: 3, iters: 498, time: 1.576) G_GAN: -4.525 G_L1: 868.176 D_real+fake: -4.038 
(epoch: 3, iters: 598, time: 1.570) G_GAN: -2.673 G_L1: 343.490 D_real+fake: -2.612 
(epoch: 3, iters: 698, time: 1.603) G_GAN: -7.571 G_L1: 1158.532 D_real+fake: -4.671 
(epoch: 3, iters: 798, time: 1.604) G_GAN: -0.318 G_L1: 356.402 D_real+fake: -2.414 
(epoch: 3, iters: 898, time: 1.605) G_GAN: -11.851 G_L1: 311.121 D_real+fake: -2.122 
(epoch: 3, iters: 998, time: 1.592) G_GAN: 1.583 G_L1: 829.704 D_real+fake: -4.154 
(epoch: 3, iters: 1098, time: 1.606) G_GAN: -3.420 G_L1: 504.306 D_real+fake: -2.622 
(epoch: 4, iters: 47, time: 1.613) G_GAN: -8.276 G_L1: 1054.697 D_real+fake: -3.584 
(epoch: 4, iters: 147, time: 1.609) G_GAN: 1.051 G_L1: 215.188 D_real+fake: -1.506 
(epoch: 4, iters: 247, time: 1.601) G_GAN: -11.817 G_L1: 684.125 D_real+fake: -3.432 
(epoch: 4, iters: 347, time: 1.581) G_GAN: -3.271 G_L1: 994.294 D_real+fake: -5.021 
(epoch: 4, iters: 447, time: 1.592) G_GAN: -3.650 G_L1: 389.164 D_real+fake: -2.423 
(epoch: 4, iters: 547, time: 1.595) G_GAN: -3.810 G_L1: 1144.334 D_real+fake: -5.380 
(epoch: 4, iters: 647, time: 1.559) G_GAN: 3.938 G_L1: 345.655 D_real+fake: -2.336 
(epoch: 4, iters: 747, time: 1.595) G_GAN: 1.600 G_L1: 544.278 D_real+fake: -1.985 
(epoch: 4, iters: 847, time: 1.595) G_GAN: -7.305 G_L1: 621.652 D_real+fake: -3.171 
(epoch: 4, iters: 947, time: 1.594) G_GAN: -0.413 G_L1: 1302.229 D_real+fake: -5.236 
(epoch: 4, iters: 1047, time: 1.605) G_GAN: -0.774 G_L1: 798.018 D_real+fake: -3.537 
(epoch: 4, iters: 1147, time: 1.596) G_GAN: -3.252 G_L1: 1484.482 D_real+fake: -5.844 
(epoch: 5, iters: 96, time: 1.609) G_GAN: 1.555 G_L1: 63.082 D_real+fake: -0.571 
(epoch: 5, iters: 196, time: 1.585) G_GAN: 0.006 G_L1: 899.560 D_real+fake: -5.028 
(epoch: 5, iters: 296, time: 1.607) G_GAN: -2.126 G_L1: 723.236 D_real+fake: -3.036 
(epoch: 5, iters: 396, time: 1.594) G_GAN: -14.791 G_L1: 297.097 D_real+fake: -1.663 
(epoch: 5, iters: 496, time: 1.591) G_GAN: 7.289 G_L1: 446.201 D_real+fake: -2.745 
(epoch: 5, iters: 596, time: 1.553) G_GAN: 7.950 G_L1: 225.402 D_real+fake: -0.825 
(epoch: 5, iters: 696, time: 1.598) G_GAN: 2.693 G_L1: 200.648 D_real+fake: -1.029 
(epoch: 5, iters: 796, time: 1.609) G_GAN: -4.665 G_L1: 775.756 D_real+fake: -2.370 
(epoch: 5, iters: 896, time: 1.579) G_GAN: 2.902 G_L1: 1576.311 D_real+fake: -8.179 
(epoch: 5, iters: 996, time: 1.595) G_GAN: 2.775 G_L1: 1223.708 D_real+fake: -5.057 
(epoch: 5, iters: 1096, time: 1.611) G_GAN: 1.373 G_L1: 249.408 D_real+fake: -2.096 
(epoch: 6, iters: 45, time: 1.647) G_GAN: 3.333 G_L1: 767.927 D_real+fake: -2.939 
(epoch: 6, iters: 145, time: 1.659) G_GAN: -10.486 G_L1: 938.239 D_real+fake: -2.588 
(epoch: 6, iters: 245, time: 1.603) G_GAN: 6.374 G_L1: 317.994 D_real+fake: -2.159 
(epoch: 6, iters: 345, time: 1.626) G_GAN: -0.446 G_L1: 238.948 D_real+fake: -1.622 
(epoch: 6, iters: 445, time: 1.607) G_GAN: -4.509 G_L1: 492.104 D_real+fake: -2.438 
================ Training Loss (Wed Jun 13 16:42:10 2018) ================
================ Training Loss (Wed Jun 13 17:43:09 2018) ================
================ Training Loss (Sat Jun 30 02:04:15 2018) ================
================ Training Loss (Sat Jun 30 02:08:03 2018) ================
================ Training Loss (Sat Jun 30 02:10:02 2018) ================
================ Training Loss (Sat Jun 30 02:12:01 2018) ================
================ Training Loss (Sat Jun 30 16:29:47 2018) ================
================ Training Loss (Sat Jun 30 16:30:25 2018) ================
================ Training Loss (Sat Jun 30 16:39:21 2018) ================
================ Training Loss (Sat Jun 30 16:40:15 2018) ================
================ Training Loss (Sat Jun 30 16:40:45 2018) ================
================ Training Loss (Sat Jun 30 16:49:03 2018) ================
================ Training Loss (Sat Jun 30 16:50:57 2018) ================
================ Training Loss (Sat Jun 30 16:53:58 2018) ================
================ Training Loss (Sat Jun 30 16:54:25 2018) ================
================ Training Loss (Sat Jun 30 16:55:20 2018) ================
================ Training Loss (Sat Jun 30 16:56:40 2018) ================
================ Training Loss (Sat Jun 30 16:57:02 2018) ================
================ Training Loss (Sat Jun 30 17:00:03 2018) ================
================ Training Loss (Sat Jun 30 17:01:57 2018) ================
================ Training Loss (Sat Jun 30 17:02:19 2018) ================
================ Training Loss (Sat Jun 30 17:03:29 2018) ================
================ Training Loss (Sat Jun 30 17:04:18 2018) ================
================ Training Loss (Sat Jun 30 17:04:39 2018) ================
================ Training Loss (Sat Jun 30 17:04:54 2018) ================
================ Training Loss (Sat Jun 30 17:06:12 2018) ================
================ Training Loss (Sat Jun 30 17:38:09 2018) ================
================ Training Loss (Sat Jun 30 17:39:00 2018) ================
================ Training Loss (Sat Jun 30 17:42:05 2018) ================
================ Training Loss (Sat Jun 30 17:45:49 2018) ================
================ Training Loss (Sat Jun 30 17:46:09 2018) ================
================ Training Loss (Sat Jun 30 17:46:39 2018) ================
================ Training Loss (Sat Jun 30 17:47:44 2018) ================
================ Training Loss (Sat Jun 30 17:48:38 2018) ================
================ Training Loss (Sat Jun 30 17:55:19 2018) ================
================ Training Loss (Sat Jun 30 17:57:01 2018) ================
================ Training Loss (Sat Jun 30 17:57:42 2018) ================
================ Training Loss (Sat Jun 30 17:58:11 2018) ================
================ Training Loss (Sat Jun 30 17:59:03 2018) ================
================ Training Loss (Sat Jun 30 18:00:41 2018) ================
================ Training Loss (Sat Jun 30 18:00:54 2018) ================
================ Training Loss (Sat Jun 30 18:12:32 2018) ================
================ Training Loss (Sat Jun 30 18:14:11 2018) ================
================ Training Loss (Sat Jun 30 18:15:48 2018) ================
================ Training Loss (Sat Jun 30 18:16:32 2018) ================
================ Training Loss (Sat Jun 30 18:16:49 2018) ================
================ Training Loss (Sat Jun 30 18:17:29 2018) ================
================ Training Loss (Sat Jun 30 18:18:14 2018) ================
================ Training Loss (Sat Jun 30 18:19:11 2018) ================
================ Training Loss (Sat Jun 30 18:20:10 2018) ================
================ Training Loss (Sat Jun 30 18:21:39 2018) ================
================ Training Loss (Sat Jun 30 18:25:17 2018) ================
================ Training Loss (Sat Jun 30 18:27:05 2018) ================
================ Training Loss (Sat Jun 30 18:29:38 2018) ================
================ Training Loss (Sat Jun 30 18:30:45 2018) ================
================ Training Loss (Sat Jun 30 18:32:57 2018) ================
================ Training Loss (Sat Jun 30 18:33:33 2018) ================
================ Training Loss (Sat Jun 30 18:33:48 2018) ================
================ Training Loss (Sat Jun 30 18:38:07 2018) ================
